{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data_clean\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('./data_clean/data_clean.json', orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_row(row):\n",
    "    # Unir las características adicionales en una sola cadena de texto\n",
    "    genre = row[\"genres\"]\n",
    "    keywords = row[\"keywords\"]\n",
    "\n",
    "    combined_text = f\"{keywords} [SEP] Genre: {genre}\"\n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # Importar tqdm para la barra de progreso\n",
    "import time  # Importar time para calcular el tiempo transcurrido\n",
    "\n",
    "# Cargar modelo y tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Función para obtener embeddings por lote\n",
    "def get_bert_embeddings(texts, batch_size=32):\n",
    "    embeddings = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)  # Mover el modelo a GPU si está disponible\n",
    "\n",
    "    # Inicializar tqdm para la barra de progreso\n",
    "    pbar = tqdm(total=len(texts), desc=\"Processing texts\", unit=\"texts\")\n",
    "    start_time = time.time()  # Tiempo de inicio del procesamiento\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i : i + batch_size]\n",
    "        tokens = tokenizer(\n",
    "            batch_texts, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**tokens)\n",
    "        batch_embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        embeddings.append(batch_embeddings)\n",
    "\n",
    "        # Actualizar la barra de progreso\n",
    "        pbar.update(len(batch_texts))\n",
    "\n",
    "        # Calcular tiempo transcurrido y estimar tiempo restante\n",
    "        elapsed_time = time.time() - start_time\n",
    "        texts_per_sec = (i + len(batch_texts)) / elapsed_time\n",
    "        remaining_time = (len(texts) - (i + len(batch_texts))) / texts_per_sec\n",
    "\n",
    "        # Actualizar descripción de la barra de progreso con el tiempo estimado\n",
    "        pbar.set_postfix({\"ETA\": f\"{remaining_time:.1f} sec\"})\n",
    "\n",
    "    pbar.close()  # Cerrar la barra de progreso al finalizar\n",
    "    return torch.cat(embeddings, dim=0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['combined'] = df.apply(preprocess_row, axis=1)\n",
    "combined_texts = df['combined'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8637     The St. Valentine's Day Massacre\n",
      "423                          A Bronx Tale\n",
      "2801                            The Limey\n",
      "38914                        Café Society\n",
      "289                Leon: The Professional\n",
      "13825                           Dillinger\n",
      "11487                   The Good Shepherd\n",
      "3221                            Key Largo\n",
      "8352                             Scarface\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Obtener embeddings\n",
    "embeddings_np = get_bert_embeddings(combined_texts, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Memento', 'Ratatouille', 'The Moustache', 'New York Stories', 'Wild at Heart', 'The Skeleton Key', 'Interstate 60', 'In Her Shoes', 'New Best Friend', 'Just Like a Woman', 'The Vagrant', 'Secret Window', 'Frailty', 'Home for the Holidays']\n"
     ]
    }
   ],
   "source": [
    "# Crear el índice en FAISS\n",
    "d = embeddings_np.shape[1]\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(embeddings_np)\n",
    "\n",
    "# Función para obtener recomendaciones con FAISS\n",
    "import numpy as np\n",
    "\n",
    "def get_recommendations_faiss(titles, df, index, embeddings, k=10):\n",
    "    # Obtener los índices de las películas que coinciden con los títulos\n",
    "    indices = [df[df['title'] == title].index[0] for title in titles]\n",
    "    \n",
    "    # Obtener los embeddings promedio de las películas\n",
    "    avg_embedding = np.mean(embeddings[indices], axis=0, keepdims=True)\n",
    "    \n",
    "    # Buscar los k vecinos más cercanos al embedding promedio\n",
    "    D, I = index.search(avg_embedding, k)\n",
    "    \n",
    "    # I[0][1:] contiene los índices de las películas más similares (excluyendo las ingresadas)\n",
    "    movie_indices = I[0][1:]\n",
    "    \n",
    "    # Devolver los títulos de las películas recomendadas\n",
    "    return df['title'].iloc[movie_indices].tolist()\n",
    "\n",
    "\n",
    "# Ejemplo de uso\n",
    "recommended_movies_faiss = get_recommendations_faiss(['Ratatouille',\"Memento\"], df, index, embeddings_np, k=15)\n",
    "print(recommended_movies_faiss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar embeddings y el índice en FAISS\n",
    "np.save('./assets/embeddings.npy', embeddings_np)\n",
    "\n",
    "d = embeddings_np.shape[1]\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(embeddings_np)\n",
    "faiss.write_index(index, './assets/embedding_index.faiss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
