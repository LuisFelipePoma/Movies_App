{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7565 entries, 0 to 7564\n",
      "Data columns (total 29 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     7565 non-null   int64  \n",
      " 1   keywords               7565 non-null   object \n",
      " 2   characters             7565 non-null   object \n",
      " 3   actors                 7565 non-null   object \n",
      " 4   director               7565 non-null   object \n",
      " 5   crew                   7565 non-null   object \n",
      " 6   adult                  7565 non-null   object \n",
      " 7   belongs_to_collection  7565 non-null   object \n",
      " 8   budget                 7565 non-null   int64  \n",
      " 9   genres                 7565 non-null   object \n",
      " 10  homepage               1303 non-null   object \n",
      " 11  imdb_id                7563 non-null   object \n",
      " 12  original_language      7565 non-null   object \n",
      " 13  original_title         7565 non-null   object \n",
      " 14  overview               7565 non-null   object \n",
      " 15  popularity             7565 non-null   float64\n",
      " 16  poster_path            7545 non-null   object \n",
      " 17  production_companies   7565 non-null   object \n",
      " 18  production_countries   7565 non-null   object \n",
      " 19  release_date           7565 non-null   int64  \n",
      " 20  revenue                7565 non-null   int64  \n",
      " 21  runtime                7565 non-null   float64\n",
      " 22  spoken_languages       7565 non-null   object \n",
      " 23  status                 7565 non-null   object \n",
      " 24  tagline                7565 non-null   object \n",
      " 25  title                  7565 non-null   object \n",
      " 26  video                  7565 non-null   bool   \n",
      " 27  vote_average           7565 non-null   float64\n",
      " 28  vote_count             7565 non-null   int64  \n",
      "dtypes: bool(1), float64(3), int64(5), object(20)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Read data_clean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_json('./data_clean/data_clean.json', orient=\"records\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_row(row):\n",
    "    # Unir las características adicionales en una sola cadena de texto\n",
    "    genre = row[\"genres\"]\n",
    "    keywords = row[\"keywords\"]\n",
    "    overview = row[\"overview\"]\n",
    "    director = row[\"director\"]\n",
    "    actor = row[\"actors\"]\n",
    "    combined_text = f\" {genre} [SEP] keywords: {keywords} [SEP] overview: {overview} [SEP] director: {director} [SEP] actors: {actor}\"\n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning de BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/miniconda3/envs/tf/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # Importar tqdm para la barra de progreso\n",
    "import time  # Importar time para calcular el tiempo transcurrido\n",
    "\n",
    "# Cargar modelo y tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Función para obtener embeddings por lote\n",
    "def get_bert_embeddings(texts, batch_size=32):\n",
    "    embeddings = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)  # Mover el modelo a GPU si está disponible\n",
    "\n",
    "    # Inicializar tqdm para la barra de progreso\n",
    "    pbar = tqdm(total=len(texts), desc=\"Processing texts\", unit=\"texts\")\n",
    "    start_time = time.time()  # Tiempo de inicio del procesamiento\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i : i + batch_size]\n",
    "        tokens = tokenizer(\n",
    "            batch_texts, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**tokens)\n",
    "        batch_embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        embeddings.append(batch_embeddings)\n",
    "\n",
    "        # Actualizar la barra de progreso\n",
    "        pbar.update(len(batch_texts))\n",
    "\n",
    "        # Calcular tiempo transcurrido y estimar tiempo restante\n",
    "        elapsed_time = time.time() - start_time\n",
    "        texts_per_sec = (i + len(batch_texts)) / elapsed_time\n",
    "        remaining_time = (len(texts) - (i + len(batch_texts))) / texts_per_sec\n",
    "\n",
    "        # Actualizar descripción de la barra de progreso con el tiempo estimado\n",
    "        pbar.set_postfix({\"ETA\": f\"{remaining_time:.1f} sec\"})\n",
    "\n",
    "    pbar.close()  # Cerrar la barra de progreso al finalizar\n",
    "    return torch.cat(embeddings, dim=0).cpu().numpy() # Combina todos los embeddings en un solo tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['combined'] = df.apply(preprocess_row, axis=1)\n",
    "combined_texts = df['combined'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing texts: 100%|██████████| 7565/7565 [11:16<00:00, 11.18texts/s, ETA=0.0 sec]  \n"
     ]
    }
   ],
   "source": [
    "# Obtener embeddings\n",
    "embeddings_np = get_bert_embeddings(combined_texts, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar embeddings y el índice en FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./assets/embeddings.npy', embeddings_np) #array de numpy que contiene los embeddings de las películas.\n",
    "\n",
    "d = embeddings_np.shape[1]  # Dimensiones de los embeddings\n",
    "index = faiss.IndexFlatL2(d)  # Crea un índice Faiss de tipo FlatL2 con las dimensiones d\n",
    "index.add(embeddings_np)  # Añade los embeddings al índice Faiss\n",
    "faiss.write_index(index, './assets/embedding_index.faiss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recomendar Peliculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3049  608  549 1631  579  660   96 1231    0 2857  976 2787  838 1101]\n",
      "['Bee Movie', 'An American Tail', 'Doctor Dolittle', 'Finding Nemo', 'Gremlins 2: The New Batch', 'Pleasantville', 'The Flintstones', 'The Great Outdoors', 'Toy Story', 'Ratatouille', 'Return to Me', 'Open Season', 'Home Alone 2: Lost in New York', 'How the Grinch Stole Christmas']\n"
     ]
    }
   ],
   "source": [
    "# Función para obtener recomendaciones con FAISS\n",
    "def get_recommendations_faiss(titles, df, index, embeddings, k=10):\n",
    "    # Obtener los índices de las películas que coinciden con los títulos\n",
    "    indices = [df[df['title'] == title].index[0] for title in titles]\n",
    "    \n",
    "    # Obtener los embeddings promedio de las películas\n",
    "    avg_embedding = np.mean(embeddings[indices], axis=0, keepdims=True)\n",
    "    # Buscar los k vecinos más cercanos al embedding promedio\n",
    "    D, I = index.search(avg_embedding, k)\n",
    "    \n",
    "    # I[0][1:] contiene los índices de las películas más similares (excluyendo las ingresadas)\n",
    "    movie_indices = I[0][1:]\n",
    "    print(movie_indices)\n",
    "    # Devolver los títulos de las películas recomendadas\n",
    "    return df['title'].iloc[movie_indices].tolist()\n",
    "\n",
    "\n",
    "# Ejemplo de uso\n",
    "recommended_movies_faiss = get_recommendations_faiss(['Ratatouille',\"Toy Story\"], df, index, embeddings_np, k=15)\n",
    "print(recommended_movies_faiss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3049    5559\n",
       "608     4978\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[3049, 608]][\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Similaridad Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calcular matriz de similitud coseno entre todos los pares de embeddings\n",
    "similarity_matrix = cosine_similarity(embeddings_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Búsqueda de Vecinos Más Cercanos con Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el índice Faiss\n",
    "index = faiss.read_index(\"./assets/embedding_index.faiss\")\n",
    "\n",
    "# Realizar búsqueda de vecinos más cercanos para una película de ejemplo\n",
    "query_embedding = embeddings_np[0]  # Tomar el primer embedding como ejemplo\n",
    "query_embedding = query_embedding.reshape(\n",
    "    1, -1\n",
    ")  # Reshape para que sea compatible con Faiss\n",
    "\n",
    "# Buscar los vecinos más cercanos\n",
    "k = 5  # Número de vecinos más cercanos a buscar\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "# Mostrar los índices de los vecinos más cercanos y sus distancias\n",
    "print(\"Índices de vecinos más cercanos:\", indices)\n",
    "print(\"Distancias a los vecinos más cercanos:\", distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluación de Clasificación o Agrupamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de etiquetas basadas en género (solo a modo ilustrativo)\n",
    "# TODO FIX THIS S...\n",
    "genres = df[\"genres\"].to_list() \n",
    "labels = [genres.index(genre) for genre in genres]  # Convertir géneros en etiquetas numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de evaluación de clustering con K-means\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "# Asumiendo que tienes etiquetas conocidas en 'labels'\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(embeddings_np)\n",
    "predicted_labels = kmeans.labels_\n",
    "\n",
    "# Calcular Adjusted Rand Index entre las etiquetas predichas y las verdaderas\n",
    "ari = adjusted_rand_score(labels, predicted_labels)\n",
    "print(\"Adjusted Rand Index:\", ari)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicalabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Vecinos Más Cercanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reducción de dimensionalidad con PCA\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_pca = pca.fit_transform(embeddings_np)\n",
    "\n",
    "# Visualización de los vecinos más cercanos en el espacio reducido\n",
    "def plot_nearest_neighbors(movie_indices, embeddings_pca, df):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(embeddings_pca[:, 0], embeddings_pca[:, 1], alpha=0.5, label='Películas')\n",
    "    plt.scatter(embeddings_pca[movie_indices, 0], embeddings_pca[movie_indices, 1], color='red', label='Películas seleccionadas')\n",
    "    \n",
    "    for idx in movie_indices:\n",
    "        plt.annotate(df['title'].iloc[idx], (embeddings_pca[idx, 0], embeddings_pca[idx, 1]))\n",
    "    \n",
    "    plt.xlabel('Componente Principal 1')\n",
    "    plt.ylabel('Componente Principal 2')\n",
    "    plt.title('Visualización de Vecinos Más Cercanos')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Ejemplo de uso\n",
    "titles = ['The Dark Knight', 'Inception']\n",
    "indices = [df[df['title'] == title].index[0] for title in titles]\n",
    "\n",
    "avg_embedding = np.mean(embeddings_np[indices], axis=0, keepdims=True)\n",
    "D, I = index.search(avg_embedding, k=10)\n",
    "\n",
    "plot_nearest_neighbors(I[0], embeddings_pca, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_movie_features(movie_indices, df):\n",
    "    for idx in movie_indices:\n",
    "        print(f\"Título: {df['title'].iloc[idx]}\")\n",
    "        print(f\"Género: {df['genres'].iloc[idx]}\")\n",
    "        print(f\"Descripción: {df['overview'].iloc[idx]}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Ejemplo de uso\n",
    "analyze_movie_features(I[0], df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Crear un explainer SHAP\n",
    "explainer = shap.Explainer(model, embeddings_np)\n",
    "shap_values = explainer(embeddings_np)\n",
    "\n",
    "# Resumen de importancia de características\n",
    "shap.summary_plot(shap_values, features=embeddings_np, feature_names=df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estudios de Casos y Validación Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_recommendations(titles, recommended_titles):\n",
    "    for i, title in enumerate(titles):\n",
    "        print(f\"Para la película '{title}', las recomendaciones son:\")\n",
    "        print(\", \".join(recommended_titles[i]))\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# Ejemplo de uso\n",
    "titles = [\"The Dark Knight\", \"Inception\"]\n",
    "recommended_titles = [\n",
    "    get_recommendations_faiss([title], df, index, embeddings_np) for title in titles\n",
    "]\n",
    "\n",
    "analyze_recommendations(titles, recommended_titles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
